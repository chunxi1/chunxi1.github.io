{"meta":{"title":"Chunxi's Blog","subtitle":"ababab","description":"","author":"Chunxi1","url":"https://clouddd.cc","root":"/"},"pages":[{"title":"","date":"2020-11-10T09:31:28.524Z","updated":"2020-11-10T09:31:28.524Z","comments":true,"path":"about/index.html","permalink":"https://clouddd.cc/about/index.html","excerpt":"","text":"下面写关于自己的内容"},{"title":"所有标签","date":"2020-11-11T00:57:32.854Z","updated":"2020-11-11T00:57:32.854Z","comments":true,"path":"blog/tags/index.html","permalink":"https://clouddd.cc/blog/tags/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2020-11-11T00:56:50.731Z","updated":"2020-11-11T00:56:50.731Z","comments":true,"path":"blog/categories/index.html","permalink":"https://clouddd.cc/blog/categories/index.html","excerpt":"","text":""},{"title":"我的朋友们","date":"2020-11-11T01:04:29.582Z","updated":"2020-11-11T01:04:29.582Z","comments":true,"path":"blog/friends/index.html","permalink":"https://clouddd.cc/blog/friends/index.html","excerpt":"这里写友链上方的内容。","text":"这里写友链上方的内容。 这里可以写友链页面下方的文字备注，例如自己的友链规范、示例等。"},{"title":"","date":"2020-11-11T01:04:11.020Z","updated":"2020-11-11T01:04:11.020Z","comments":true,"path":"blog/mylist/index.html","permalink":"https://clouddd.cc/blog/mylist/index.html","excerpt":"","text":""},{"title":"","date":"2020-11-11T01:13:06.438Z","updated":"2020-11-11T01:13:06.438Z","comments":true,"path":"404.html","permalink":"https://clouddd.cc/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"}],"posts":[{"title":"CentOS-7.2 搭建 ambari2.6.0.0","slug":"ambari","date":"2020-10-27T16:00:00.000Z","updated":"2020-11-11T16:00:00.000Z","comments":true,"path":"2020/10/28/ambari/","link":"","permalink":"https://clouddd.cc/2020/10/28/ambari/","excerpt":"Ambari 是一种基于 Web 的工具，支持 Apache Hadoop 集群的供应、管理和监控。Ambari已支持大多数Hadoop组件，包括HDFS、MapReduce、Hive、Pig、 Hbase、Zookeeper、Sqoop和Hcatalog等。","text":"Ambari 是一种基于 Web 的工具，支持 Apache Hadoop 集群的供应、管理和监控。Ambari已支持大多数Hadoop组件，包括HDFS、MapReduce、Hive、Pig、 Hbase、Zookeeper、Sqoop和Hcatalog等。 开始之前从新安装的系统，没有任何配置开始。以两台节点配置安装(master节点 和 slave节点)ambari 支持在线安装和离线安装，由于在线安装过慢，采用离线安装的方式 双节点 关闭防火墙systemctl disable firewalld systemctl stop firewalld 关闭SELinux临时 setenforce 0 永久关闭 vi /etc/sysconfig/selinux SELINUX=disabled 配置主机名、IP 映射vi hosts 192.168.0.128 master master.hadoop 192.168.0.129 slave slave.hadoop master节点 hostnamectl set-hostname master slave节点 hostnamectl set-hostname slave 互相 ping 测试联通性 master节点 ping slave.hadoop slave节点 ping master.hadoop 配置本地源master节点 安装 Apache HTTP 服务yum install httpd -y systemctl start httpd systemctl enable httpd 下载安装资源HDP 资源 wget http://public-repo-1.hortonworks.com/HDP/centos7/2.x/updates/2.6.1.0/HDP-2.6.1.0-centos7-rpm.tar.gz wget http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.21/repos/centos7/HDP-UTILS-1.1.0.21-centos7.tar.gz ambari 资源 wget http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.6.0.0/ambari-2.6.0.0-centos7.tar.gz 其他版本参考以下下载地址： Ambari | HDP 和 HDP UTILS 解压下载的压缩包 mkdir /opt/HDP-UTILS-1.1.0.21 tar -zxvf HDP-UTILS-1.1.0.21-centos7.tar.gz -C /opt/HDP-UTILS-1.1.0.21 tar -zxvf HDP-2.6.1.0-centos7-rpm.tar.gz -C /opt tar -zxvf ambari-2.6.0.0-centos7.tar.gz -C /opt 放置资源位置 mkdir /var/www/html/HDP-2.6.1.0/ mv /opt/HDP/centos7/* /var/www/html/HDP-2.6.1.0/ mv /opt/HDP-UTILS-1.1.0.21 /var/www/html/ mkdir /var/www/html/ambari/ mv /opt/ambari/centos7/2.6.0.0-267 /var/www/html/ambari/ 配置 ambari、HDP、HDP-UTILS 本地源cp /var/www/html/ambari/2.6.0.0-267/ambari.repo /etc/yum.repos.d/ vi ambari.repo #VERSION_NUMBER=2.6.0.0-267 [ambari-2.6.0.0] name=ambari Version - ambari-2.6.0.0 baseurl=http://master/ambari/2.6.0.0-267/ gpgcheck=1 gpgkey=http://master/ambari/2.6.0.0-267/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins enabled=1 priority=1 repo文件复制给 slave 节点 scp /etc/yum.repos.d/ambari.repo root@slave:/etc/yum.repos.d/ 双节点 更新 yum 源 yum clean all yum makecache 安装集群所需环境安装 ntp 时间同步服务master节点 yum install ntp -y vi /etc/ntp.conf 注释以下四行： server 0.centos.pool.ntp.org iburst server 1.centos.pool.ntp.org iburst server 2.centos.pool.ntp.org iburst server 3.centos.pool.ntp.org iburst 添加以下两行： server 127.127.1.0 fudge 127.127.1.0 stratum 10 开启ntpd systemctl start ntpdsystemctl enable ntpd slave节点 yum install ntpdate -y systemctl enable ntpdate ntpdate master.hadoop 禁用Transparent Huge Pages(内存大页)双节点 [root@master ~]# cat /sys/kernel/mm/transparent_hugepage/enabled [always] madvise never [root@master ~]# echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled [root@master ~]# echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag [root@master ~]# cat /sys/kernel/mm/transparent_hugepage/enabled always madvise [never] 安装Java JDKambari 需要 jdk7 或 jdk8 本例采用 jdk-8u77 (1.8.0_77) 双节点 mkdir /usr/jdk64 tar -zxvf jdk-8u77-linux-x64.tar.gz -C /usr/jdk64 编辑环境变量： vi /etc/profile 首行添加两行： export JAVA_HOME=/usr/jdk64/jdk1.8.0_77/ export PATH=$JAVA_HOME/bin:$PATH 验证： source /etc/profile java -version 安装 MariaDB 数据库master节点 yum install mariadb mariadb-server mysql-connector-java -y systemctl enable mariadb systemctl start mariadb 安全配置向导 mysql_secure_installation Enter current password for root (enter for none): Set root password? [Y/n] y # 是否设置root用户密码，输入y并回车或直接回车 New password: # 设置root用户的密码 为bigdata Re-enter new password: # 再次输入一遍 Password updated successfully! Reloading privilege tables.. ... Success! Remove anonymous users? [Y/n] y # 是否删除匿名用户,生产环境建议删除 ... Success! Disallow root login remotely? [Y/n] n # 是否禁止root远程登录 ... skipping. Remove test database and access to it? [Y/n] y # 是否删除test数据库 - Dropping test database... ... Success! - Removing privileges on test database... ... Success! Reload privilege tables now? [Y/n] y # 是否重新加载权限表 ... Success! Thanks for using MariaDB! 创建 ambari 数据库 mysql -uroot -pbigdata create database ambari; grant all privileges on ambari.* to &#39;ambari&#39;@&#39;localhost&#39; identified by &#39;bigdata&#39;; grant all privileges on ambari.* to &#39;ambari&#39;@&#39;%&#39; identified by &#39;bigdata&#39;; use ambari; source /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql quit; 安装 Ambarimaster节点 vi /etc/profile export buildNumber=2.6.0.0 安装ambari-server yum install ambari-server -y ambari-server setup 安装向导： Customize user account for ambari-server daemon [y/n] (n)? n # 自定义ambari服务器后台程序的用户帐户 [1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8 [2] Oracle JDK 1.7 + Java Cryptography Extension (JCE) Policy Files 7 [3] Custom JDK ============================================================================== Enter choice (1): 3 # 输入选项 Path to JAVA_HOME: /usr/jdk64/jdk1.8.0_77/ # 输入JAVA安装路径 Enter advanced database configuration [y/n] (n)? y # 输入高级数据库配置 Choose one of the following options: [1] - PostgreSQL (Embedded) [2] - Oracle [3] - MySQL / MariaDB [4] - PostgreSQL [5] - Microsoft SQL Server (Tech Preview) [6] - SQL Anywhere [7] - BDB ============================================================================== Enter choice (1): 3 # 选择数据库 Hostname (localhost): # 主机名，回车默认 Port (3306): # 数据库端口，回车默认 Database name (ambari): # 数据库名，回车默认 Username (ambari): # 用户名，回车默认 Enter Database Password (bigdata): # 数据库密码，回车默认 Proceed with configuring remote database connection properties [y/n] (y)? y # 继续配置远程数据库连接属性 Adjusting ambari-server permissions and ownership... Ambari Server &#39;setup&#39; completed successfully. 配置驱动 ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar 启动 ambari-server 服务 ambari-server start 安装 ambari-agent双节点 yum install ambari-agent -y vi /etc/ambari-agent/conf/ambari-agent.ini [server] hostname=master.hadoop 重启 ambari-agent restart tail -f /var/log/ambari-agent/ambari-agent.log # 持续查看日志文件 重启成功后，在浏览器输入默认 Ambari 地址：http://master:8080 出现登录界面，默认账户：admin、密码：admin 登录界面 安装 HDP 配置集群登录成功点击 Launch Install Wizard 按钮进行集群配置 设置集群名称，接着下一步 选择版本选择版本 设置 HDP 安装源设置安装源 设置集群信息设置集群信息 点击 Register and Confirm 后会显示警告，提示需要提前安装 ambari-agent ，之前已经安装过了，直接下一步。 主机检查主机检查 选择要安装的服务最低需要 HDFS YARN+MapReduce2 Ambari Metrics 选择服务 服务分配 Master服务分配 分配 Slaves 和 Clients分配 Slaves 和 Clients 自定义服务需要填入密码 这里为 000000 到下一步 自定义服务 安装开始并进行测试全部绿色就 ok 了 安装开始并进行测试 安装完成安装完成","categories":[],"tags":[{"name":"bigdata","slug":"bigdata","permalink":"https://clouddd.cc/tags/bigdata/"},{"name":"ambari","slug":"ambari","permalink":"https://clouddd.cc/tags/ambari/"}],"author":"chunxi1"},{"title":"虚拟机搭建先电大数据平台","slug":"vm_bigdata","date":"2020-09-16T16:00:00.000Z","updated":"2020-09-16T16:00:00.000Z","comments":true,"path":"2020/09/17/vm_bigdata/","link":"","permalink":"https://clouddd.cc/2020/09/17/vm_bigdata/","excerpt":"按照顺序，如果使用 vmware 搭建 iaas 再在里面的云平台搭建大数据平台，可能会出现内存、处理器资源不足，遂推出直接在虚拟机中安装的方法","text":"按照顺序，如果使用 vmware 搭建 iaas 再在里面的云平台搭建大数据平台，可能会出现内存、处理器资源不足，遂推出直接在虚拟机中安装的方法 准备CentOS-7-x86_64-DVD-1511.iso XianDian-BigData-v2.2.iso XianDian-IaaS-v2.2.iso qemu-img 准备工作转换镜像格式 VMware 不支持 qcow2 格式的镜像，将其转换成 vmdk 格式，替换掉创建的虚拟机的 vmdk (虚拟硬盘) 下载：qemu-img for Windows 工具解压到桌面 000.png 用 7zip、winrar 等解压工具打开 XianDian-IaaS-v2.2.iso 将 images\\CentOS_7.2_x86_64_XD.qcow2 提取到桌面 在 qemu-img 文件夹，按住 shift + 鼠标右键，选择 在此处打开 Powershell 窗口 打开 Powershell 窗口 输入命令，转换镜像 .\\qemu-img.exe convert -f qcow2 ..\\CentOS_7.2_x86_64_XD.qcow2 -O vmdk ..\\CentOS_7.2_x86_64_XD.vmdk 可以看见桌面生成的vmdk镜像文件 虚拟机创建在 VMware 按照下表创建虚拟机： 节点名 内存 CPU 硬盘 网络模式 master 8G 2 100G NAT slave 4G 2 100G NAT 光盘镜像选择稍后安装。网络使用DHCP自动获取IP 添加光盘镜像创建完毕后，为 master 节点添加为双光驱 在 虚拟机设置 里面添加。 cdrom 原先自带的光驱 ISO 镜像使用 CentOS-7-x86_64-DVD-1511.iso ，后添加的光驱使用 XianDian-BigData-v2.2.iso 镜像 注意都要勾选 已连接 打开虚拟机所在的目录，将开头桌面生成的 vmdk 镜像文件，重命名为虚拟机的名称 (master.vmdk 和 slave.vmdk)。进行覆盖 替换 slave 节点同理 扩展磁盘替换掉虚拟硬盘之后，会发现两台虚拟机硬盘只有 8GB。需要扩大到 100GB 003.png 在 虚拟机设置 - 硬盘 - 扩展 设置最大磁盘大小为 100GB ，点击 扩展 扩展 接下来开机 虚拟机配置用户名 root 密码 000000 镜像默认网卡配置的是 DHCP 自动获取 双节点 systemctl restart network ip a 得到 ip ，使用 Xshell、secureCRT 连上 (本文为 master：172.0.0.130、slave：172.0.0.131) 配置主机名master节点 hostnamectl set-hostname master slave节点 hostnamectl set-hostname slave 扩展分区磁盘扩展后，分区并没有扩展，执行扩展分区的操作 使用 fdisk 工具进行分区 fdisk /dev/sda Welcome to fdisk (util-linux 2.23.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): Command (m for help): p # 打印存在的分区 Disk /dev/sda: 107.4 GB, 107374182400 bytes, 209715200 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x000af71d Device Boot Start End Blocks Id System /dev/sda1 2048 209715199 104856576 83 Linux # 可以看出来只有1个分区，调整它的大小 Command (m for help): d # 删除分区 Selected partition 1 Partition 1 is deleted # 只有一个分区，所以直接删除了 Command (m for help): n # 新建分区 Partition type: p primary (0 primary, 0 extended, 4 free) e extended Select (default p): p # p - 主分区 Partition number (1-4, default 1): 1 # 分区号(默认1) First sector (2048-209715199, default 2048): # 起始扇区(默认2048) Using default value 2048 Last sector, +sectors or +size&#123;K,M,G&#125; (2048-209715199, default 209715199): # 结束扇区(回车默认占完剩下空间) Using default value 209715199 Partition 1 of type Linux and of size 100 GiB is set Command (m for help): w # 保存退出 保存后会出现警告，进行分区表刷新 partprobe /dev/sda 还会出现警告，重启系统 reboot 使用 xfs_growfs 对挂载目录在线扩容 [root@master ~]# xfs_growfs /dev/sda1 meta-data=/dev/sda1 isize=256 agcount=51, agsize=524224 blks = sectsz=512 attr=2, projid32bit=1 = crc=0 finobt=0 data = bsize=4096 blocks=26214144, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=0 log =internal bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 查看分区情况 [root@master ~]# df -h Filesystem Size Used Avail Use% Mounted on /dev/sda1 100G 8.6G 92G 9% / devtmpfs 3.9G 0 3.9G 0% /dev tmpfs 3.9G 12K 3.9G 1% /dev/shm tmpfs 3.9G 17M 3.9G 1% /run tmpfs 3.9G 0 3.9G 0% /sys/fs/cgroup 配置 hosts双节点 vi /etc/hosts 添加两行： 172.0.0.130 master master.hadoop 172.0.0.131 slave slave.hadoop 以两节点 ip a 命令所获得的 ip 为准 互相 ping 测试 hosts 文件联通性 master节点 ping slave.hadoop slave节点 ping master.hadoop 修改 yum 源安装软件采用本地 yum 源的方式安装软件，将两光驱的镜像挂载到 /opt/centos 和 /opt/ambari 下 master节点 mkdir /opt/centos mkdir /opt/ambari mount /dev/sr0 /opt/centos # sr0 为原先自带的光驱 mount /dev/sr1 /opt/ambari # sr1 为后来添加的光驱 双节点 rm -rf /etc/yum.repos.d/* vi /etc/yum.repos.d/ambari.repo master节点 yum 源 slave节点 yum 源 安装 vsftpdmaster节点 通过 vsftpd 远程传送 yum 仓库 yum install vsftpd -y vi /etc/vsftpd/vsftpd.conf 在首行添加一行： anon_root=/opt/ 开启 vsftpd systemctl start vsftpd systemctl enable vsftpd 双节点 yum clean all yum list # 此镜像的防火墙默认关闭 安装软件master节点 yum install httpd -y 将 /opt/ambari 文件夹中 HDP-2.6.1.0 和 HDP-UTILS-1.1.0.21 两个文件夹拷贝到 /var/www/html 目录下。 cp -rf /opt/ambari/HDP-2.6.1.0/ /var/www/html cp -rf /opt/ambari/HDP-UTILS-1.1.0.21/ /var/www/html 开启httpd master节点 systemctl start httpd systemctl enable httpd systemctl status httpd 安装ntp master节点 yum install ntp -y vi /etc/ntp.conf 注释以下四行： server 0.centos.pool.ntp.org iburst server 1.centos.pool.ntp.org iburst server 2.centos.pool.ntp.org iburst server 3.centos.pool.ntp.org iburst 添加以下两行： server 127.127.1.0 fudge 127.127.1.0 stratum 10 开启ntpd systemctl start ntpd systemctl enable ntpd slave节点 yum install ntpdate -y systemctl enable ntpdate ntpdate master.hadoop 禁用Transparent Huge Pages双节点 [root@master ~]# cat /sys/kernel/mm/transparent_hugepage/enabled [always] madvise never [root@master ~]# echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled [root@master ~]# echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag [root@master ~]# cat /sys/kernel/mm/transparent_hugepage/enabled always madvise [never] 安装Java JDK将 jdk 安装包复制到 slave 的 /opt 下 master节点 scp -r /opt/ambari/jdk-8u77-linux-x64.tar.gz 172.0.0.301:/opt/ 双节点 解压 jdk： mkdir /usr/jdk64/ master节点 tar -zxvf /opt/ambari/jdk-8u77-linux-x64.tar.gz -C /usr/jdk64/ slave节点 tar -zxvf /opt/jdk-8u77-linux-x64.tar.gz -C /usr/jdk64/ 编辑环境变量： vi /etc/profile 首行添加两行： export JAVA_HOME=/usr/jdk64/jdk1.8.0_77/ export PATH=$JAVA_HOME/bin:$PATH 验证： source /etc/profile java -version 之后的操作与在云平台创建的大数据一样，跳转到 配置ambari-server 继续后续配置。","categories":[{"name":"先电","slug":"先电","permalink":"https://clouddd.cc/categories/%E5%85%88%E7%94%B5/"}],"tags":[{"name":"vmware","slug":"vmware","permalink":"https://clouddd.cc/tags/vmware/"},{"name":"bigdata","slug":"bigdata","permalink":"https://clouddd.cc/tags/bigdata/"},{"name":"先电","slug":"先电","permalink":"https://clouddd.cc/tags/%E5%85%88%E7%94%B5/"}],"author":"chunxi1"},{"title":"大数据搭建","slug":"bigdata","date":"2019-01-10T16:00:00.000Z","updated":"2020-09-07T16:00:00.000Z","comments":true,"path":"2019/01/11/bigdata/","link":"","permalink":"https://clouddd.cc/2019/01/11/bigdata/","excerpt":"云主机创建在平台 管理员 - 系统 - 云主机类型 创建云主机类型：","text":"云主机创建在平台 管理员 - 系统 - 云主机类型 创建云主机类型： 名称 VCPU 内存 根磁盘 4g 2 4096MB 100G 8g 2 8192MB 100G 在 项目 - 计算 - 云主机 创建云主机： Instance Name 源 flavor 网络 master ContOS_7.2 8g int slave ContOS_7.2 4g int 为两台云主机分别绑定浮动IP (本文以 master:192.168.200.102, slave:192.168.200.103 为示例) 配置主机名master节点 hostnamectl set-hostname master slave节点 hostnamectl set-hostname slave 配置 hosts双节点 vi /etc/hosts 001.png 注意：1.其中保持 ip 与在云主机绑定的 int 内网 ip 一致2.主机名映射采用FQDN格式。 互相 ping 测试 hosts 文件联通性 master节点 ping slave.hadoop slave节点 ping master.hadoop 修改 yum 源安装软件采用 ftp 的方式获取 yum 仓库,在 controller节点 将 XianDian-BigData-v2.2.iso 挂载复制到 /opt/ambari 下 双节点 rm -rf /etc/yum.repos.d/* vi /etc/yum.repos.d/ambari.repo 002.png yum clean all yum list master节点 yum install httpd -y 从 controller节点 将 /opt/ambari 文件夹中 HDP-2.6.1.0 和 HDP-UTILS-1.1.0.21 两个文件夹拷贝到 master节点 /var/www/html 目录下。 controller节点 scp -r /opt/ambari/HDP-2.6.1.0/ 192.168.200.102:/var/www/html scp -r /opt/ambari/HDP-UTILS-1.1.0.21/ 192.168.200.102:/var/www/html 开启httpd master节点 systemctl start httpd systemctl enable httpd systemctl status httpd 安装ntp master节点 yum install ntp -y vi /etc/ntp.conf 注释以下四行： server 0.centos.pool.ntp.org iburst server 1.centos.pool.ntp.org iburst server 2.centos.pool.ntp.org iburst server 3.centos.pool.ntp.org iburst 添加以下两行： server 127.127.1.0 fudge 127.127.1.0 stratum 10 开启ntpd systemctl start ntpd systemctl enable ntpd slave节点 yum install ntpdate -y systemctl enable ntpdate ntpdate master.hadoop 禁用Transparent Huge Pages双节点 [root@master ~]# cat /sys/kernel/mm/transparent_hugepage/enabled [always] madvise never [root@master ~]# echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled [root@master ~]# echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag [root@master ~]# cat /sys/kernel/mm/transparent_hugepage/enabled always madvise [never] 安装Java JDK将 controller节点 的 jdk 安装包复制到 master 和 slave 的 /opt 下 controller节点 scp -r /opt/ambari/jdk-8u77-linux-x64.tar.gz 192.168.200.102://opt/ scp -r /opt/ambari/jdk-8u77-linux-x64.tar.gz 192.168.200.103://opt/ 双节点 解压 jdk： mkdir /usr/jdk64/ tar -zxvf /opt/jdk-8u77-linux-x64.tar.gz -C /usr/jdk64/ 编辑环境变量： vi /etc/profile 首行添加两行： export JAVA_HOME=/usr/jdk64/jdk1.8.0_77/ export PATH=$JAVA_HOME/bin:$PATH 验证： source /etc/profile java -version 配置ambari-servermaster节点 yum install ambari-server -y 安装 MariaDB 数据库 yum install mariadb mariadb-server mysql-connector-java -y systemctl enable mariadb systemctl start mariadb 配置 MariaDB mysql_secure_installation 安全配置向导 Enter current password for root (enter for none): Set root password? [Y/n] y # 是否设置root用户密码，输入y并回车或直接回车 New password: # 设置root用户的密码 Re-enter new password: # 再次输入一遍 Password updated successfully! Reloading privilege tables.. ... Success! Remove anonymous users? [Y/n] y # 是否删除匿名用户,生产环境建议删除 ... Success! Disallow root login remotely? [Y/n] n # 是否禁止root远程登录 ... skipping. Remove test database and access to it? [Y/n] y # 是否删除test数据库 - Dropping test database... ... Success! - Removing privileges on test database... ... Success! Reload privilege tables now? [Y/n] y # 是否重新加载权限表 ... Success! Thanks for using MariaDB! 创建 ambari 数据库 mysql -uroot -pbigdata 在 mariadb 中执行以下操作 create database ambari; grant all privileges on ambari.* to &#39;ambari&#39;@&#39;localhost&#39; identified by &#39;bigdata&#39;; grant all privileges on ambari.* to &#39;ambari&#39;@&#39;%&#39; identified by &#39;bigdata&#39;; use ambari; source /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql quit; 安装配置ambari-servermaster节点 vi /etc/profile 添加一行： export buildNumber=2.6.0.0 安装ambari-server ambari-server setup 安装向导： Customize user account for ambari-server daemon [y/n] (n)? n # 自定义ambari服务器后台程序的用户帐户 [1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8 [2] Oracle JDK 1.7 + Java Cryptography Extension (JCE) Policy Files 7 [3] Custom JDK ============================================================================== Enter choice (1): 3 # 输入选项 Path to JAVA_HOME: /usr/jdk64/jdk1.8.0_77/ # 输入JAVA安装路径 Enter advanced database configuration [y/n] (n)? y # 输入高级数据库配置 Choose one of the following options: [1] - PostgreSQL (Embedded) [2] - Oracle [3] - MySQL / MariaDB [4] - PostgreSQL [5] - Microsoft SQL Server (Tech Preview) [6] - SQL Anywhere [7] - BDB ============================================================================== Enter choice (1): 3 # 选择数据库 Hostname (localhost): # 主机名，回车默认 Port (3306): # 数据库端口，回车默认 Database name (ambari): # 数据库名，回车默认 Username (ambari): # 用户名，回车默认 Enter Database Password (bigdata): # 数据库密码，回车默认 Proceed with configuring remote database connection properties [y/n] (y)? y # 继续配置远程数据库连接属性 Adjusting ambari-server permissions and ownership... Ambari Server &#39;setup&#39; completed successfully. 配置 ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar 启动 ambari-server 服务 ambari-server start 配置ambari-agent双节点 yum install ambari-agent -y vi /etc/ambari-agent/conf/ambari-agent.ini 修改如下样式： [server] hostname=master.hadoop 重启、监视： ambari-agent restart tail -f /var/log/ambari-agent/ambari-agent.log 进入平台进入先电大数据平台(http://master:8080) 用户名、密码：admin admin 启动安装向导 名称： HDP 接着下一步 选择版本 003.png 安装选项 004.png 确认主机直接下一步 选择服务选择 HDFS YARN+MapReduce2 Ambari Metrics 下一步 分配 Master 005.png 分配 Slaves 和 Clients 006.png 自定义服务这里填入密码 000000 到最后下一步 007.png 最后到概括直接部署，等待安装。完毕后两个主机全绿色就 ok 了 008.png 给个最后的截图： 009.png","categories":[{"name":"先电","slug":"先电","permalink":"https://clouddd.cc/categories/%E5%85%88%E7%94%B5/"}],"tags":[{"name":"bigdata","slug":"bigdata","permalink":"https://clouddd.cc/tags/bigdata/"},{"name":"先电","slug":"先电","permalink":"https://clouddd.cc/tags/%E5%85%88%E7%94%B5/"}],"author":"chunxi1"},{"title":"Paas搭建","slug":"paas","date":"2018-12-04T16:00:00.000Z","updated":"2020-09-07T16:00:00.000Z","comments":true,"path":"2018/12/05/paas/","link":"","permalink":"https://clouddd.cc/2018/12/05/paas/","excerpt":"云主机创建在 项目 - 计算 - 云主机 创建云主机：","text":"云主机创建在 项目 - 计算 - 云主机 创建云主机： Instance Name 源 flavor 网络 server ContOS_7.2 m1.medium int client ContOS_7.2 m1.medium int 为两台云主机分别绑定浮动IP (本文以 client:192.168.200.102, server:192.168.200.103 为示例) 配置主机名server节点 hostnamectl set-hostname server client节点 hostnamectl set-hostname client 配置 hosts双节点 vi /etc/hosts 添加以下内容： 192.168.200.102 client 192.168.200.103 server 互相 ping 测试 hosts 文件联通性 server节点 ping client client节点 ping server 关闭防火墙、配置 iptables双节点 systemctl stop firewalld systemctl disable firewalld 配置 iptables iptables -L # 查看 iptables -F # 规则 iptables -X # 策略 iptables -Z # 用户数据 iptables -L 修改系统内核文件双节点 vi /etc/sysctl.conf 添加以下内容： net.ipv4.ip_forward = 1 net.ipv4.conf.default.rp_filter = 0 net.ipv4.conf.all.rp_filter = 0 检验： sysctl -p sysctl -p 配置yum源采用 ftp 的方式获取 yum 仓库,在 controller节点 将 XianDian-PaaS-v2.2.iso 挂载复制到 /opt/paas 下 双节点 rm -rf /etc/yum.repos.d/* vi /etc/yum.repos.d/ftp.repo 修改如下： [docker] name=docker baseurl=ftp://192.168.100.10/paas/docker gpgcheck=0 enabled=1 接着 yum clean all yum list 安装 docker双节点 yum install docker -y 修改 docker 仓库地址 vi /etc/sysconfig/docker 添加如下 ADD_REGISTRY=&#39;--add-registry 192.168.200.103:5000&#39; INSECURE_REGISTRY=&#39;--insecure-registry 192.168.200.103:5000&#39; 使配置生效 systemctl daemon-reload # 生效 systemctl restart docker # 启动 systemctl enable docker # 开机自启 docker info # 查询地址是否修改正确 上传仓库地址使用镜像server节点 cd /opt/images/rancher1.6.5 导入 docker load -i registry_latest.tar load : 导入、加载、解压save:导出-i : 指定导入的文件，代替 STDIN-q : 精简输出信息 查看仓库镜像 docker images 创建容器 docker run -d -p 5000:5000 --restart=always --name registry docker.io/registry:latest Run: 创建一个新的容器并运行一个命令-d: 后台运行容器，并返回容器ID-p: 指定端口映射 查看一遍，根据 ID 打上标签 docker images docker tag &lt;ID&gt; 192.168.200.103:5000/registry:latest # c9bd19d022f6 tag: 标记本地镜像，将其归入某一仓库 推送 docker push 192.168.200.103:5000/registry:latest push: 将本地的镜像上传到镜像仓库,要先登陆到镜像仓库docker rmi 镜像ID: 删除仓库 docker push 启动容器，命令：docker start 容器ID或容器名&gt;重启容器，命令：docker restart 容器ID或容器名&gt;停止容器，命令：docker stop 容器ID或容器名&gt;强制停止容器，命令：docker kill 容器ID或容器名 上传 rancher_server 服务 rancher_server_v1.6.5.tar docker load -i rancher_server_v1.6.5.tar docker images docker tag f89070da7581 192.168.200.103:5000/rancher/server:v1.6.5 # f89070da7581 docker push 192.168.200.103:5000/rancher/server:v1.6.5 docker run -d --restart=unless-stopped -p 8080:8080 rancher/server:v1.6.5 # 启动服务 docker logs -f &lt;进程ID&gt; # 查看 rancher_server 部署进程 此时可以进入网页 http://192.168.200.103:8080进入网页后停止日志信息 （ctrl+c） logs: 获取容器的日志-f: 跟踪日志输出–since: 显示某个开始时间的所有日志-t: 显示时间戳–tail: 仅列出最新N条容器日志 将/opt/images/rancher1.6.5里所有的包都推送到仓库ll rancher_agent_v1.2.5.tar docker load -i rancher_agent_v1.2.5.tar docker images docker tag &lt;ID&gt; 192.168.200.103:5000/rancher/agent:v1.2.5 docker push 192.168.200.103:5000/rancher/agent:v1.2.5 rancher_dns_v0.15.1.tar docker load -i rancher_dns_v0.15.1.tar docker images docker tag &lt;ID&gt; 192.168.200.103:5000/rancher/dns:v0.15.1 docker push 192.168.200.103:5000/rancher/dns:v0.15.1 rancher_healthcheck_v0.3.1.tar docker load -i rancher_healthcheck_v0.3.1.tar docker images docker tag &lt;ID&gt; 192.168.200.103:5000/rancher/healthcheck:v0.3.1 docker push 192.168.200.103:5000/rancher/healthcheck:v0.3.1 rancher_metadata_v0.9.2.tar docker load -i rancher_metadata_v0.9.2.tar docker images docker tag &lt;ID&gt; 192.168.200.103:5000/rancher/metadata:v0.9.2 docker push 192.168.200.103:5000/rancher/metadata:v0.9.2 rancher_net_holder.tar docker load -i rancher_net_holder.tar docker images docker tag &lt;ID&gt; 192.168.200.103:5000/rancher/net:holder docker push 192.168.200.103:5000/rancher/net:holder rancher-net_v0.11.3.tar docker load -i rancher-net_v0.11.3.tar docker images docker tag &lt;ID&gt; 192.168.200.103:5000/rancher/net:v0.11.3 docker push 192.168.200.103:5000/rancher/net:v0.11.3 rancher_network-manager_v0.7.4.tar docker load -i rancher_network-manager_v0.7.4.tar docker images docker tag &lt;ID&gt; 192.168.200.103:5000/rancher/network-manager:v0.7.4 docker push 192.168.200.103:5000/rancher/network-manager:v0.7.4 rancher_scheduler_v0.8.2.tar docker load -i rancher_scheduler_v0.8.2.tar docker images docker tag &lt;ID&gt; 192.168.200.103:5000/rancher/scheduler:v0.8.2 docker push 192.168.200.103:5000/rancher/scheduler:v0.8.2 进入网页云计算基础架构服务平台(http://server:8080) 平台 右下角English改为简体中文 中文 系统管理 - 系统设置 系统设置 网页拉到最下边 - “我确认已经知道修改高级设置可能导致问题” 下边 拉到最下边找到 registry.dedfault= 这一栏右边修改仓库地址 仓库地址 拉到最上边设置仓库地址为你的 server 地址，保存 保存 Default - 环境管理 环境管理 添加环境 添加环境 名称为：router，创建 创建 环境创建成功 成功 进入 router 环境 router环境 添加主机 添加主机 添加 client 节点 ip（图中为实例 ip）将第5步的脚步复制到 client 节点运行关闭 添加主机 运行结果 添加主机 切换到 应用 - 基础环境所有基础服务状态为 active 即代表 paas 平台搭建完毕 添加主机","categories":[{"name":"先电","slug":"先电","permalink":"https://clouddd.cc/categories/%E5%85%88%E7%94%B5/"}],"tags":[{"name":"先电","slug":"先电","permalink":"https://clouddd.cc/tags/%E5%85%88%E7%94%B5/"},{"name":"paas","slug":"paas","permalink":"https://clouddd.cc/tags/paas/"}],"author":"anhuicdx"},{"title":"Iaas搭建","slug":"iaas","date":"2018-09-30T16:00:00.000Z","updated":"2020-08-24T16:00:00.000Z","comments":true,"path":"2018/10/01/iaas/","link":"","permalink":"https://clouddd.cc/2018/10/01/iaas/","excerpt":"文中的 10节点 表示 controller节点，20节点 表示 compute节点；网卡名默认 eth0 和 enp7s0 表示内网， eth1 和 enp8s0 为外网 (相对服务器的内外网)。","text":"文中的 10节点 表示 controller节点，20节点 表示 compute节点；网卡名默认 eth0 和 enp7s0 表示内网， eth1 和 enp8s0 为外网 (相对服务器的内外网)。 如果不在虚拟机内搭建，跳到系统安装 虚拟机配置内容 VMware 配置双节点 001.png Vmnet1 002.png Vmnet8 003.png 双节点 开启虚拟机,禁用网卡命名规则,在开机界面按 &#8593; 键，选中 Install CentOS 7 再按下 Tab ,在后面添加代码(如下图): net.ifnames=0 biosdevname=0 004.png 系统安装 硬盘配置10节点 选择 I will configure 然后 Done 005.png 点击自动创建 006.png 007.png 硬盘比较大时 会自动生成 /home 分区，应删除，再将根目录分区也删除、再重新创建(重新创建以自动占满 /home 留下的空间)。 20节点 前面一样，后面在分区时，减小根分区，为后面的 cinder 和 swift 服务留空。服务器应为2个服务共 200 GB 、虚拟机可以留 20-10 GB (或者 20%)。 例如，这里是总共50 G 硬盘，默认分配之后，缩小10 G 008.png 网络配置双节点 配置两个节点的 eth0 (服务器默认是 enp7s0 )如下： 009.png 010.png 类似的，20节点同理。 最后，关闭打开前面的 On 保证刷新显示出来IP 。 然后开始安装 配置网络 双节点 vi /etc/sysconfig/network-scripts/ifcfg-eth0 配置好之后应该是这样： cat /etc/sysconfig/network-scripts/ifcfg-eth0 10节点 011.png 20节点 012.png 理论上只用将 ONBOOT 改为 yes 就可以了 (在前面 网络配置 可能导致没有 IPADDR 等… 的 bug，按照上图修改就可以了)。 重启网络 systemctl restart network 安装先电软件包 10节点 使用 SecureFX、Xftp 等 ftp 软件将 CentOS-7-x86_64-DVD-1511.iso 和 XianDian-IaaS-v2.2.iso 上传到/home里面 (当然镜像挂载的方法也可以)。 mount /home/CentOS-7-x86_64-DVD-1511.iso /mnt mkdir /opt/centos/ mkdir /opt/iaas/ cp -rvf /mnt/* /opt/centos/ umount /mnt/ mount /home/XianDian-IaaS-v2.2.iso /mnt cp -rvf /mnt/* /opt/iaas/ umount /mnt/ 设置10节点yum源10节点 rm -rf /etc/yum.repos.d/* #把10节点的yum源移除 vi /etc/yum.repos.d/centos.repo 013.png 验证: yum clean all yum list 安装ftp服务10节点 yum install vsftpd -y vi /etc/vsftpd/vsftpd.conf 在第一行添加: anon_root=/opt/ 启动ftp服务: systemctl start vsftpd systemctl enable vsftpd 关闭防火墙并且使其开机不自启双节点 systemctl stop firewalld systemctl disable firewalld 配置20节点yum源20节点 mv /etc/yum.repos.d/* /opt/ #20节点的yum源在/opt下备份 vi /etc/yum.repos.d/centos.repo 014.png 验证: yum clean all yum list 设置脚本环境变量双节点 yum install iaas-xiandian -y vi /etc/xiandian/openrc.sh 015.png (其中，第75行和89行是上面硬盘配置给cinder、swift留空的分区名称，具体名称以下面分区步骤之后的名称为准。) 可以将10节点编辑好的文件传到20节点上。 10节点 scp /etc/xiandian/openrc.sh 192.168.100.20:///etc/xiandian 检验: 20节点 cat /etc/xiandian/openrc.sh 为cinder和swift分区20节点 以50 GB，每个服务给5 GB的方式为例。（具体大小看自己情况，仅参考） [root@localhost ~]# lsblk #列出所有可用块设备的信息 NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 50G 0 disk ├─sda1 8:1 0 500M 0 part /boot └─sda2 8:2 0 39.5G 0 part └─centos-root 253:0 0 39.5G 0 lvm / sr0 11:0 1 1024M 0 rom [root@localhost ~]# [root@localhost ~]# [root@localhost ~]# parted /dev/sda GNU Parted 3.1 Using /dev/sda Welcome to GNU Parted! Type &#39;help&#39; to view a list of commands. (parted) (parted) p #显示分区表、可用设备、可用空间、所有找到的分区或特定分区 Model: VMware, VMware Virtual S (scsi) Disk /dev/sda: 53.7GB Sector size (logical/physical): 512B/512B Partition Table: msdos Disk Flags: Number Start End Size Type File system Flags 1 1049kB 525MB 524MB primary xfs boot 2 525MB 43.0GB 42.4GB primary lvm (parted) (parted) mkpart cinder #创建分区 parted: invalid token: cinder Partition type? primary/extended? p #主分区/扩展分区？扩展 File system type? [ext2]? ext4 #Ext4——第四代扩展文件系统 Start? 43.0GB #从上个分区的 End 开始（Number 2） End? 48.0GB #给 5 GB的空间 (parted) (parted) p Model: VMware, VMware Virtual S (scsi) Disk /dev/sda: 53.7GB Sector size (logical/physical): 512B/512B Partition Table: msdos Disk Flags: Number Start End Size Type File system Flags 1 1049kB 525MB 524MB primary xfs boot 2 525MB 43.0GB 42.4GB primary lvm 3 43.0GB 48.0GB 5046MB primary (parted) (parted) mkpart swift parted: invalid token: swift Partition type? primary/extended? p File system type? [ext2]? ext4 Start? 48.0GB End? 53.0GB (parted) (parted) p Model: VMware, VMware Virtual S (scsi) Disk /dev/sda: 53.7GB Sector size (logical/physical): 512B/512B Partition Table: msdos Disk Flags: Number Start End Size Type File system Flags 1 1049kB 525MB 524MB primary xfs boot 2 525MB 43.0GB 42.4GB primary lvm 3 43.0GB 48.0GB 5046MB primary 4 48.0GB 53.0GB 5001MB primary (parted) (parted) q #退出parted Information: You may need to update /etc/fstab. [root@localhost ~]# [root@localhost ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 50G 0 disk ├─sda1 8:1 0 500M 0 part /boot ├─sda2 8:2 0 39.5G 0 part │ └─centos-root 253:0 0 39.5G 0 lvm / ├─sda3 8:3 0 4.7G 0 part #cinder分区 └─sda4 8:4 0 4.7G 0 part #swift分区 sr0 11:0 1 1024M 0 rom [root@localhost ~]# 最后生成的 cinder、swift 分区，填在上面脚本环境变量 openrc.sh 里面 ( (parted) h 可以查看parted命令帮助。) 安装脚本 脚本执行是不可逆的，保证严格的顺序，执行错误就要重来。双节点脚本建议同时安装（虚拟机可以创建快照） 其中 […] 表示两个名字不同的脚本（例如 iaas-install-nova-controller.sh 和 iaas-install-nova-compute.sh。） 可以参照 openrc.sh 里面的顺序来安装 双节点 iaas-pre-host.sh 双节点 CRT断开连接重新登录一下 ( Ctrl + D ) 10节点 iaas-install-mysql.sh (数据库) 10节点 iaas-install-keystone.sh (认证服务) 10节点 iaas-install-glance.sh (镜像服务) 双节点 iaas-install-nova-co[…].sh (计算服务) 双节点 iaas-install-neutron-co[…].sh (网络服务) 双节点 iaas-install-neutron-co[…]-gre.sh (gre网络模式) 注意： 这里20节点安装 gre.sh 完成之后没有返回提示为正常；10节点安装最后会出现： Unknown operation ‘enabled’. 这是脚本错误，查看脚本文件： cat /usr/local/bin/iaas-install-neutron-controller-gre.sh ······ systemctl restart neutron-lbaas-agent systemctl enabled neutron-lbaas-agent enabled 改为 enable，执行 systemctl enable neutron-lbaas-agent 。 10节点 iaas-install-dashboard.sh (Dashboard服务) 这里安装完Dashboard服务可以跳转到上传镜像，这样安装的平台为最简安装 (之后的也可以以后安装) 双节点 iaas-install-cinder-co[…].sh (cinder块储存服务) 10节点 source /etc/keystone/admin-openrc.sh 双节点 iaas-install-swift-co[…].sh (swift对象储存服务) 执行过程中需要确认登录 controller 节点和输入 controller 节点 root 用户密码 10节点 iaas-install-trove.sh (trove服务) 注意： 安装Trove服务之前需要配置好网络（flat 或 gre）,创建好子网，并确认系统已经安装 swift 和 cinder 两个服务，否则安装会失败。 10节点 iaas-install-heat.sh (heat编配服务) 双节点 iaas-install-ceilometer-co[…].sh (ceilometer监控服务) 10节点 iaas-install-alarm.sh (alarm监控服务) 上传镜像10节点 source /etc/keystone/admin-openrc.sh cat /usr/local/bin/iaas-install-trove.sh 复制 iaas-install-trove.sh 尾部的一段代码，修改为如下执行： glance image-create --name &quot; CentOS_7.2_x86_64&quot; --disk-format qcow2 --container-format bare --progress &lt; /opt/iaas/images/CentOS_7.2_x86_64_XD.qcow2 进入平台 点击下面链接： 云计算基础架构服务平台 一、规则在 项目 - 计算 - 访问&amp;安全 删除全部规则 添加所有 ICMP协议 + 入&amp;出口 + 远程CIDR + 0.0.0.0/0所有 TCP 协议 + 入&amp;出口 + 远程CIDR + 0.0.0.0/0所有 UDP 协议 + 入&amp;出口 + 远程CIDR + 0.0.0.0/0 016.png 二、网络在 管理员 - 系统 - 网络 创建① 名称 ext 项目 admin 类型 GRE 段ID 192 *[x] 外部网络 之后在 ext 网络中创建 子网名称 ext-sub 网络地址: 192.168.200.0/24 网关IP: 192.168.200.1在详情页地址池:192.168.200.100,192.168.200.200 (100到200) 创建② 名称 int 项目 admin 类型 GRE 段ID 10创建子网 int-sub 地址 10.0.0.0/24 + 网关IP: 10.0.0.1在详情页地址池: 10.0.0.100,10.0.0.200 (100到200) 三、路由在 项目 - 网络 - 路由新建路由 router 外部网络 ext之后在 router 中添加接口 子网 int：10.0.0.0/24 (int-sub) 在cmd中测试路由(ping 192.168.200.101) 整合资源 10节点 修改 openrc.sh 把compute节点的IP和主机名改为controller节点的IP和主机名(20-&gt;10) 017.png 执行脚本 iaas-install-nova-compute.sh 在平台 管理员 - 系统 - 虚拟机管理器 观察，主机名存在controller即操作成功。","categories":[{"name":"先电","slug":"先电","permalink":"https://clouddd.cc/categories/%E5%85%88%E7%94%B5/"}],"tags":[{"name":"先电","slug":"先电","permalink":"https://clouddd.cc/tags/%E5%85%88%E7%94%B5/"},{"name":"iaas","slug":"iaas","permalink":"https://clouddd.cc/tags/iaas/"}],"author":"chunxi1"},{"title":"Hello World","slug":"hello-world","date":"2018-09-29T16:00:00.000Z","updated":"2018-09-29T16:00:00.000Z","comments":true,"path":"2018/09/30/hello-world/","link":"","permalink":"https://clouddd.cc/2018/09/30/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.","categories":[],"tags":[]}],"categories":[{"name":"先电","slug":"先电","permalink":"https://clouddd.cc/categories/%E5%85%88%E7%94%B5/"}],"tags":[{"name":"bigdata","slug":"bigdata","permalink":"https://clouddd.cc/tags/bigdata/"},{"name":"ambari","slug":"ambari","permalink":"https://clouddd.cc/tags/ambari/"},{"name":"vmware","slug":"vmware","permalink":"https://clouddd.cc/tags/vmware/"},{"name":"先电","slug":"先电","permalink":"https://clouddd.cc/tags/%E5%85%88%E7%94%B5/"},{"name":"paas","slug":"paas","permalink":"https://clouddd.cc/tags/paas/"},{"name":"iaas","slug":"iaas","permalink":"https://clouddd.cc/tags/iaas/"}]}